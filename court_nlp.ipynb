{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from zipfile import ZipFile\n",
    "from tqdm import tqdm\n",
    "import glob, re, pandas as pd, numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from pdb import set_trace as breakpoint # like in 3.7\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "with ZipFile('./data/court2018.zip') as zf:\n",
    "    decisions = zf.namelist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_paragraphs(doc):\n",
    "    '''\n",
    "    breaks text into paragraphs. also strips indents with whitespace\n",
    "    '''\n",
    "    # split and strip\n",
    "    doc = map(str.strip, doc.split('\\n'))\n",
    "    # delete empty lines - result of multiple newlines\n",
    "    doc = filter(lambda paragraph: len(paragraph) > 0,\n",
    "                 doc)\n",
    "    # remove duplicate whitespace\n",
    "    return list(map(lambda paragraph: re.sub('\\s+', ' ', paragraph),\n",
    "                    doc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Which articles are used in the decision?\n",
    "\n",
    "1. Filter list of paragraphs to leave only ones mentioning article"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['СВ Царичанського ВП Новомосковського ВП ГУНП в Дніпропетровській області проводиться досудове розслідування у кримінальному провадженні №1201804060000253 від 19.05.2018р. за ознаками вчинення злочину, передбаченого ч. 1 ст.115 КК України.',\n",
       " 'Таким чином, ОСОБА_4, підозрюється в умисному вбивстві, тобто умисному протиправному заподіянні смерті ОСОБА_3, тобто у вчиненні злочину, передбаченого ч. 1 ст. 115 КК України.',\n",
       " '25.05.2018 року по вказаному кримінальному провадженню ОСОБА_4 було оголошено про підозру у вчиненні ним злочину, передбаченого ч. 1 ст. 115 КК України.',\n",
       " \"Згідно ч. 1 ст. 242 КПК України, експертиза проводиться експертною установою, експертом або експертами, за дорученням слідчого судді чи суду, наданим за клопотанням сторони кримінального провадження або, якщо для з'ясування обставин, що мають значення для кримінального провадження необхідні спеціальні знання.\"]"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[p for p in paragraphs\n",
    " if re.search('\\d{1,4} *ст[\\. ]|ст\\. *ст\\. *\\d{1,4} *- *\\d{1,4}', p)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### КК or КПК?\n",
    "2. Rule-based approach = suffering, but often it is the simpliest and most efficient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "code_folding": [
     44
    ]
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 18025/18025 [00:19<00:00, 904.18it/s]\n"
     ]
    }
   ],
   "source": [
    "df = []\n",
    "article_freq = Counter()\n",
    "\n",
    "with ZipFile('./data/court2018.zip') as zf:\n",
    "    for fn in tqdm(decisions):\n",
    "        with zf.open(fn) as f:\n",
    "            \n",
    "            category = re.search('\\d+_(\\d{4}).txt', fn).group(1)\n",
    "            doc = f.read().decode()\n",
    "            paragraphs = split_paragraphs(doc)\n",
    "            \n",
    "            doc_articles = set()\n",
    "            \n",
    "            for p in paragraphs:\n",
    "                if re.search('\\d{1,4} *ст[\\. ]|ст\\. *ст\\. *\\d{1,4} *- *\\d{1,4}', p):\n",
    "                    found = re.findall('ст[\\. ]*(\\d{1,4})| ст\\. *ст\\. *(\\d{1,4} *- *\\d{1,4})', p)\n",
    "                    matches = set()\n",
    "                    [matches.update(list(match)) for match in found]\n",
    "                    matches.discard('')\n",
    "                    \n",
    "                    # Append the code of law of article\n",
    "                    # it is always after the No of article\n",
    "                    for article in list(matches):\n",
    "                        position = re.search(f'ст[\\. ]*{article}', p\n",
    "                                    ).span()[-1]\n",
    "                        ccu = re.search('кк укра[їи]| крим[іи]нал\\w+ +кодекс',\n",
    "                                        p.lower()[position: ])\n",
    "                        cpcu = re.search('кпк укра[їи]| крим[іи]нал\\w+[\\- ]*процесуа\\w+ +кодекс',\n",
    "                                         p.lower()[position: ])\n",
    "                        if ccu and not cpcu:\n",
    "                            code = 'cc'\n",
    "                        elif not ccu and cpcu:\n",
    "                            code = 'cpc'\n",
    "                        elif ccu and cpcu:\n",
    "                            ccu_pos = ccu.span()[0]\n",
    "                            cpcu_pos = cpcu.span()[0]\n",
    "                            code = 'cpc' if cpcu_pos < ccu_pos else 'cc'\n",
    "                        else:\n",
    "                            code = 'other'\n",
    "                        matches.update([(article, code)])\n",
    "                        matches.discard(article)\n",
    "                        \n",
    "                    doc_articles.update(matches)\n",
    "            \n",
    "            for article, code in list(doc_articles):\n",
    "                if '-' in article:\n",
    "                    doc_articles.remove((article, code))\n",
    "                    a1, a2 = article.split('-')\n",
    "                    doc_articles.update([(str(a), code) for a in range(int(a1), int(a2) + 1)])\n",
    "                    \n",
    "            doc_articles = [f'{a}_{code}' for a, code in doc_articles]\n",
    "                    \n",
    "            data = {'fn': fn, 'category': category}\n",
    "            for a in doc_articles:\n",
    "                data[a] = 1\n",
    "                \n",
    "            df.append(data)\n",
    "            article_freq.update(doc_articles)\n",
    "df = pd.DataFrame(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('115_cc', 11426),\n",
       " ('15_cc', 2330),\n",
       " ('177_cpc', 2257),\n",
       " ('331_cpc', 1742),\n",
       " ('187_cc', 1706),\n",
       " ('244_cpc', 1429),\n",
       " ('242_cpc', 1419),\n",
       " ('185_cc', 1298),\n",
       " ('314_cpc', 1207),\n",
       " ('263_cc', 1076),\n",
       " ('183_cpc', 929),\n",
       " ('243_cpc', 846),\n",
       " ('336_cpc', 805),\n",
       " ('178_cpc', 800),\n",
       " ('107_cpc', 742)]"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "article_freq.most_common(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### replace not frequent articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_leave = [a for a, count in article_freq.most_common(10)]\n",
    "columns_leave = ['fn', 'category'] + columns_leave\n",
    "df = df.reindex(columns_leave, axis=1)\n",
    "df = df.fillna(0)\n",
    "# only ones that have at leat 1 article\n",
    "df = df.loc[df['115_cc'] > 0].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build a classifier "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filter data:\n",
    "1. decisions on murder with robbery\n",
    "1. without robbery (cc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False    11127\n",
       "True      3117\n",
       "Name: is_robbery, dtype: int64"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['is_robbery'] = (df['187_cc'] > 0) | (df['185_cc'] > 0)\n",
    "df.is_robbery.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define train and test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shuffle rows\n",
    "df = df.sample(frac=1)\n",
    "test_point = int(len(df) * 0.2)\n",
    "df_test = df.iloc[ :test_point].copy()\n",
    "df_train = df.iloc[test_point: ].copy()\n",
    "# df_test.to_csv('data/test_files_labels.csv', index=False)\n",
    "# df_train.to_csv('data/train_files_labels.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Мішок слів\n",
    "* Простиq підхід. Припускає, що зміст документа відображають його слова.\n",
    "* Лише слова відображають зміст документа. *Слова документа відображають зміст лише.*\n",
    "* Порядок, послідовності не мають значення"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from polyglot.text import Text\n",
    "from zipfile import ZipFile\n",
    "from tqdm import tqdm\n",
    "from utils.preprocessing import *\n",
    "from pdb import set_trace as breakpoint # like in 3.7\n",
    "import re, pymorphy2, pandas as pd, numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "107 words\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>агентства</th>\n",
       "      <th>адаптувалися</th>\n",
       "      <th>але</th>\n",
       "      <th>аналізів</th>\n",
       "      <th>анталія</th>\n",
       "      <th>басейни</th>\n",
       "      <th>беруть</th>\n",
       "      <th>блакитний</th>\n",
       "      <th>близькосхідних</th>\n",
       "      <th>більше</th>\n",
       "      <th>...</th>\n",
       "      <th>херсонці</th>\n",
       "      <th>центру</th>\n",
       "      <th>цьогорічний</th>\n",
       "      <th>чим</th>\n",
       "      <th>чиста</th>\n",
       "      <th>чого</th>\n",
       "      <th>шансом</th>\n",
       "      <th>що</th>\n",
       "      <th>юрасов</th>\n",
       "      <th>які</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 107 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   агентства  адаптувалися  але  аналізів  анталія  басейни  беруть  \\\n",
       "0          0             1    1         0        1        0       0   \n",
       "1          1             0    0         1        0        1       1   \n",
       "\n",
       "   блакитний  близькосхідних  більше ...   херсонці  центру  цьогорічний  чим  \\\n",
       "0          0               1       1 ...          1       1            1    1   \n",
       "1          1               0       0 ...          0       0            0    0   \n",
       "\n",
       "   чиста  чого  шансом  що  юрасов  які  \n",
       "0      0     1       1   2       1    1  \n",
       "1      1     0       0   1       0    0  \n",
       "\n",
       "[2 rows x 107 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vect = CountVectorizer()\n",
    "look_here = vect.fit_transform(['Цьогорічний пляжний сезон засвідчив, що херсонці адаптувалися до нової реальності й після окупації Криму навчилися більше заробляти на туризмі. Скадовськ поки не Анталія, але потенціал є. Шансом і викликом водночас для регіону є децентралізація. Успішні громади організовують курорти, зводять парки, облаштовують освітлення. Про те, чим живуть, на що сподіваються та чого остерігаються жителі південного краю, розповідають Сергій Данилов, експерт Центру близькосхідних досліджень, та соціолог Віталій Юрасов, які вивчали регіон',\n",
    "                                'Блакитний колір – показник у нормі, рожевий – забруднення перевищує допустиму межу. Відтепер можна легко відстежувати стан води у міських річках. На онлайн-карті \"Чиста вода\" Текстів і Державного агентства водних ресурсів відображені найбільші річкові басейни України та вказаний рівень забрудненості. Зауважимо, що йдеться не про русла річок повністю: на карті показано стан води у локаціях, де беруть проби для аналізів.',\n",
    "                               ])\n",
    "look_here = pd.DataFrame(look_here.toarray())\n",
    "look_here.columns = vect.get_feature_names()\n",
    "print(len(look_here.columns), 'words')\n",
    "look_here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test= pd.read_csv('data/test_files_labels.csv')\n",
    "df_train= pd.read_csv('data/train_files_labels.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenizer(text):\n",
    "    '''\n",
    "    split text into separate units - tokens. Words, punctuation, etc\n",
    "    '''\n",
    "    text = Text(text)\n",
    "    return [str(word) for word in text.words]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Tf-Idf** - не просто рахує слова. <br>Надає високе значення для слова в документі, якщо воно не дуже часто зустрічається у корпусі, проте відчутно частотніше в конкретному документі. <br> Слово \"що\" - всюди, що воно нам може сказати про документ? А слово \"журналіст\" вже вказує нам на зміст."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "bow_vectorizer = TfidfVectorizer(tokenizer=tokenizer,\n",
    "                                 ngram_range=(1, 2),\n",
    "                                 max_df=0.95, min_df=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Often we can't place all the data in memory. Generators are to help - 1 doc at a time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def traint_text_generator(df):\n",
    "    with ZipFile('./data/court2018.zip') as zf:\n",
    "        # never do nlp without progress bars - tqdm is a good one\n",
    "        for filename in tqdm(df.fn.values):\n",
    "            with zf.open(filename) as f:\n",
    "                yield f.read().decode()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11396/11396 [01:45<00:00, 107.76it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<11396x279289 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 11107337 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_bow = bow_vectorizer.fit_transform(traint_text_generator(df_train))\n",
    "train_bow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![General steps](assets/meme.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our ML data:\n",
    "- **X** - features/variables/some ugly large matrix/data\n",
    "- **y** - labels - is the decision about robbery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "regression = LogisticRegression()\n",
    "regression.fit(X=train_bow,\n",
    "               y=df_train.is_robbery.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Time to see the metrics - **evaluate model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2848/2848 [00:22<00:00, 127.43it/s]\n"
     ]
    }
   ],
   "source": [
    "test_bow = bow_vectorizer.transform(traint_text_generator(df_test))\n",
    "\n",
    "y_true = df_test.is_robbery.values\n",
    "y_pred = regression.predict(test_bow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "       True       0.99      0.78      0.87       638\n",
      "      False       0.94      1.00      0.97      2210\n",
      "\n",
      "avg / total       0.95      0.95      0.95      2848\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_true=y_true, y_pred=y_pred, labels=[True, False]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 499,  139],\n",
       "       [   7, 2203]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_true=y_true, y_pred=y_pred, labels=[True, False])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From wikipedia:<br>\n",
    "**precision** (also called positive predictive value) is the fraction of relevant instances among the retrieved instances\n",
    "<br>**recall** (also known as sensitivity) is the fraction of relevant instances that have been retrieved over the total amount of relevant instances.\n",
    "\n",
    "![Precision & recall](https://upload.wikimedia.org/wikipedia/commons/thumb/2/26/Precisionrecall.svg/440px-Precisionrecall.svg.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
